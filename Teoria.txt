Intelligenza artificiale, Machine Learning e Deep Learning.
IA: Scienza che cerca di riprodurre lâ€™intelligenza umana dei settori del apprendere, riconoscere e scegliere
ML: sottoinsieme di IA, branca del informatica che punta a creare programmi che apprendano esperienza E dopo aver migliorato le proprie prestazioni P  a seguito dello svolgimento di alcune classi di compito T 
DL: sottoinsieme di ML, utilizza le reti neurali per analizzare diversi fattori imitando il cervello umano.

Storia dellâ€™intelligenza artificiale, Origini, I due Inverni, Tempi moderni: 2011 ad oggi 
-origini: la storia delle IA parte dagli anni 40â€™ con il test di turing, il primo neurone artificiale, fino alla scrittura di alcuni chatbot
-primo inverno: meta anni 70â€™  riduzione dei fondi dovuta ai problemi di combinatoria, scarsa capacitÃ  computazionale e data set di piccole dimensioni
-secondo inverno: inizio anni 90â€™, nonostanta fosse stato inventato l'algoritmo di backpropagation le intelligenze artificiali non riescono a scalare a problemi complessi
- tempi moderni: migliora lâ€™hardware,nascono software di feature extraction e vengono sviluppati classificatori efficaci. ciÃ² porta al successo in diversi campi
-2012: nonostante le reti neurali fossero state inventate giÃ  negli anni 90â€™ solo nel 2012 si arrivÃ² alla svolta. quando una CNN batte di largo margine tutti gli altri software di riconoscimento delle immagini

Deep Learning
utilizza le reti neurali per emulare  il cervello umano.
Con il termine DNN (Deep Neural Network) si denotano reti Â« profonde Â» composte da molti livelli (almeno 2 hidden ) organizzati gerarchicamente.
 Le DNN oggi maggiormente utilizzate consistono di un numero di livelli compreso tra 7 e 50 Reti piÃ¹ profonde (100 livelli e oltre) hanno dimostrato di poter garantire prestazioni leggermente migliori, a discapito perÃ² dellâ€™efficienza

Paradigma del machine Learning vs Paradigma di programmazione tradizionale.
ML ha cambiato radicalmente lâ€™approccio dei programmatori: 
Nella programmazione classica bisogna scrivere codice per ogni passaggio del programma e situazione in cui incorre.
nel ML Ã¨ lâ€™algoritmo che Ã¨ in grado di sviluppare da sÃ© una logica propria in modo da prendere decisioni in autonomia

Preparazione dei dati (Training Set, Validation Set, Testing Set) â€“ Modello â€“ Predizione
I dati raccolti vanno etichettati, ovvero Ã¨ necessario rappresentare il contenuto semantico di essi; questi vengono poi divisi in: training set,dati su cui il modello verrÃ  addestrato; validation set, sul quale vengono messi a punto gli iperparametri; testing set, che viene utilizzato per testare il modello in modo da avere il modello la cui predizioni abbiano lâ€™errore minore possibile.
Il training set Ã¨ solitamente lâ€™insieme dei dati piÃ¹ grande

Task del Machine Learning: Classificazione, Regressione e Clustering
La classificazione: dato un insieme di classi, il programma cerca di stabilire a quale di queste classi appartiene lâ€™input.
la regressione cerca di trovare la funzione che fa da relazione tra le variabili indipendenti e dipendenti. in modo da poter predire lâ€™output di valori di input mai visti prima.
il clustering permette di raggruppare dati con caratteristiche simili, usato spesso in apprendimento non supervisionato

NecessitÃ  di una fase di feature extraction nel Machine learning
La feature extraction Ã¨ quel procedimento che permette di ricavare le caratteristiche essenziali dai dati sul quale allenare i modelli di ML. Il Deep Learning permette di evitare questa fase in quanto Ã¨ la rete neurale stessa a effettuare questa differenziazione nei dati.

Deep Learning â€“ vs Machine Learning
La differenza piÃ¹ grande tra queste due metodologie sta nella fase del feature extraction, in quanto nel ML deve essere effettuato dal programmatore, mentre nel DL La rete neurale sarÃ  in grado di estrarre le feature necessarie, a discapito di una maggiore difficoltÃ  nellâ€™apprendimento.

Classificazione degli algoritmi di Machine Learning: Algoritmi Supervisionati (Regressione e classificazione)
Vengono forniti in input i dati di partenza e il risultato che si vorrebbe ottenere, il modello ha il compito di trovare una regola generale in modo da riprodurre la relazione tra i dati e i risultati voluti.

Algoritmi non supervisionati (Clustering ed Associazione), Apprendimento Semi-supervisionato,
Il modello cerca di apprendere in autonomia la struttura dei dati in input, facendo raggruppamento in base a caratteristiche comuni. senza sapere quale Ã¨ il risultato voluto, cosÃ¬ facendo Ã¨ possibile trovare nuovi significati nei dati che non sono stati presi in considerazione. 

Apprendimento con rinforzo.
Lâ€™algoritmo interagisce con lâ€™ambiente col fine di raggiungere un determinato obiettivo. L'interazione viene gestita attraverso delle ricompense che vengono date in funzione agli obiettivi raggiunti. Con questo metodo Ã¨ lâ€™algoritmo a prendere le decisioni, senza avere definito delle regole a priori, le quali porteranno ad una penalitÃ  o un premio. Lâ€™algoritmo, quindi, impara tramite la sperimentazione in totale autonomia. Ã¨ molto efficace per domini complessi.

Reti Neurali Artificiali: Neurone Biologico e Neurone artificiale. 
Un neurone Ã¨ essenzialmente composto da una serie di collegamenti in ingresso con diversi neuroni, un collegamento in uscita e un livello di eccitamento interno. il livello di eccitamento interno varia in base ai valori di input ricevuti dai collegamenti in ingresso con gli altri neuroni. tali collegamenti inoltre hanno un â€œpesoâ€ che potrebbe diminuire o aumentare l'intensitÃ  dell input. La funzione di uscita di un neurone Ã¨ solitamente non lineare es ReLu, Sigmoide

Funzioni di attivazione. 
Si tratta di una funzione che simula il comportamento del neurone, ovvero che emetti un output solo se lâ€™input superano una certa soglia . Possono essere di diversi tipi, ma solitamente sono non lineari e derivabili in modo che la rete sia in grado di comprendere la relazione complesse tra gli input.

Percettrone a soglia e limiti.
Si tratta di un singolo neurone con funzione di attivazione a soglia, pertanto Ã¨ in grado soltanto di effettuare una separazione lineare tra due classi. Se si vogliono effettuare separazioni non lineari Ã¨ necessario aggiungere piÃ¹ percettroni fino a raggiungere il risultato desiderato.

Reti Neurali artificiali: Input Layer, Hidden Layer, Output Layer.
Input layer:livello visibile all'esterno che prende in ingresso le feature e le passa ai neuroni del livello intermedio.
Hidden Layer: si tratta di uno o piÃ¹ livelli di neuroni interconnessi compresi tra il livello di input e quello di output. vengono chiamati cosÃ¬ perchÃ© non sono visibili allâ€™ esterno.
Output Layer: Livello visibile allâ€™esterno che restituisce il risultato di tutti i layer precedenti.

Reti FeedForward, Reti ricorrenti.
Le reti FeedForward vengono chiamate cosÃ¬ perchÃ¨ i livelli sono collegati in successione, e non Ã¨ possibile avere dei collegamenti allâ€™indietro o verso lo stesso livello.
Le reti ricorrenti prevedono le connessioni di feedback sia verso neuroni dello stesso livello che allâ€™indietro, dando cosÃ¬ alla rete una memoria del passato che inciderÃ  sul risultato finale

MultiLayer Preceptron (MLP)
Sono reti fully-connected di tipo FeedForward, quindi ogni neurone sarÃ  connesso con ogni neurone dello strato successivo. Il teoremaâ€Universal Approximation Theoremâ€ afferma che una funzione che mappa intervalli di numeri reali su un intervallo di numeri reali puÃ² essere approssimata da MLP con 1 solo hidden layer

Training di una rete neurale. 
Il training delle reti neurali Ã¨ molto simile allâ€™apprendimento del cervello umano. Vengono presentati dei dati in input alla rete i quali li elabora e restituisce un risultato. Questo risultato viene confrontato con il risultato che ci si aspettava e in base a questo riscontro vengono aggiustati i pesi tra le connessioni tra i vari neuroni. Si ripete questo procedimento finchÃ© non si raggiungono i risultati aspettati. 

Forward Propagation e Backward Propagation.
Con forward propagation di intende la propagazione delle informazioni in avanti nella rete, ovvero dal layer di input verso quello di output. La backward propagation Ã¨ tecnica che utilizza alcune derivate, per svolgere piÃ¹ velocemente il gradiente della funzione costo e aggiornare i pesi

Loss Function e Funzione costo.
La loss function misura lâ€™errore tra la previsione effettuata dalla rete rispetto allâ€™output reale dei dati di training.Il training punta a minimizzare questa loss function per ogni dato. La cost function misura la perdita media sullâ€™intero dataset di addestramento.

Reti neurali Convoluzionali:
Limiti delle reti MLP nellâ€™elaborazione delle immagini. 
Per lâ€™elaborazione delle immagini, risultano troppo pesanti in quanto si utilizza un neurone per ogni pixel rappresentato, che a loro volta sono collegati a tutti i neuroni del livello successivo e quindi si avrebbe un numero di parametri eccessivo per il loro utilizzo.
Mancanza di invarianza per traslazione.
Le MLP sono totalmente dipendenti dalla posizione dei pixel, quindi una stessa immagine ma ruotata risulterÃ  totalmente diversa per la rete, e quindi produrrÃ  un risultato differente. Per ovviare a questo problema vengono utilizzate le CNN.

Le reti neurali convoluzionali (CNN) sono reti profonde (deep) ispirate alle ricerche biologiche di Hubel e Wiesel durante lo studio del cervello dei gatti.
Si Ã¨ scoperto che gli animali hanno una struttura a strati nella corteccia visiva, risultando in un approccio di tipo feed forward. CiÃ² permette ad ogni livello di astrarre sempre di piÃ¹ le parti delle immagini, partendo dal riconoscimento dei singoli elementi(es. occhio, naso, bocca,...) partendo dalle forme che lo compongono, per arrivare agli ultimi livelli che permettono la percezione degli oggetti.

celle semplici : specializzate nella rilevazione di caratteristiche locali dell'input visivo (feature extractor), (Convoluzioni)

celle complesse : specializzate nell'integrazione (pooling) delle informazioni provenienti da diverse posizioni retinotopiche per formare una rappresentazione globale dell'input visivo, preservando le caratteristiche invarianti per posizione


Architettura di una rete CNN: parte convoluzione e parte fully-connected
Una CNN Ã¨ una rete che Ã¨ divisa in una parte convoluzionale che estrae le feature ed una parte fully connected che elabora la risposta del sistema. la parte convoluzionale Ã¨ fatta da una ricorsione di tre strati, quello convoluzionale,ReLu e Pooling. il primo applica dei filtri alle matrici per evidenziare dati. il secondo esclude i valori negativi. il terzo diminuisce la dimensione della matrice. La parte fully connected invece all'inizio esegue un flattered e poi câ€™Ã¨ un MPL


Algoritmo di backpropagation per il calcolo delle derivate parziale della funzione costo rispetto ai pesi di tutti i layer .

Il metodo di backpropagation (BP) Ã¨ tuttora uno dei metodi di addestramento piÃ¹ diffusi. Il termine â€œbackpropagationâ€ (retropropagazione) Ã¨ legato essenzialmente alla tecnica utilizzata per il calcolo delle derivate della funzione di errore, basata sulle regole di derivazione delle funzioni composte Il metodo di BP Ã¨ stato utilizzato in due versioni, note rispettivamente come: 
âˆ’ BP batch, in cui i pesi vengono aggiornati dopo la presentazione di tutti i campioni del training set T; 
âˆ’ BP on-line, in cui i pesi vengono aggiornati in corrispondenza a ciascun campione di T. 

La BP batch Ã¨ definita dallâ€™iterazione dove ğ›»ğ¶ ğ‘¤ğ‘˜ Ã¨ il gradiente di C nel vettore corrente ğ‘¤ ğ‘˜ e lo scalare Î· > 0 (detto learning rate) definisce il passo lungo l'anti gradiente 

Tecniche di Ottimizzazione: metodo di discesa del gradient batch, metodo del gradiente stocastico (SGD), metodo del gradiente stocastico minibatch.
.Nel batch Gradient Descent poichÃ© stiamo utilizzando l'intero set di addestramento, i parametri verranno aggiornati solo una volta per epoca.lenta e necessita il caricamento in memoria di tutte le osservazioni

Discesa del gradiente stocastico (SGD) Se si utilizza una singola osservazione per calcolare la funzione di costo, si parla di Stochastic Gradient Descent, comunemente abbreviato SGD. Passiamo una sola osservazione alla volta, calcoliamo il costo e aggiorniamo i parametri.
piÃ¹ veloce perchÃ¨ si basa su una osservazione per ogni iterazione ma soggetta a rumore,richiede molte piÃ¹ iterazioni per apprendere

Mini-batch Stocastic Gradient Descent: Per calcolare la funzione di costo si considera un sottoinsieme dell'intero set di dati. Quindi, se ci sono ğ‘›ğ‘‡ osservazioni, il numero di osservazioni in ciascun sottoinsieme o mini-batch sarÃ  maggiore di 1 e minore di ğ‘›ğ‘‡ . via di mezzo , molto piu veloce del gradient batch perchÃ¨ il bacth Ã¨ un sottoinsieme delle osservazioni ma non soggetto al rumore del SDG.

Sotto quali condizioni, il metodo di discesa del gradiente con passo fisso converge a un punto stazionario della funzione costo, che puÃ² essere un minimo globale se la funzione Ã¨ convessa?
Condizione di Lipschitz per il gradiente: La norma del gradiente della funzione costo deve essere limitata da una costante di Lipschitz. CioÃ¨ , esiste una costante L > 0 tale che per ogni vettore di pesi x ed y, si abbia ||âˆ‡C(x) - âˆ‡C(y)|| â‰¤ L ||x - y||, dove âˆ‡C(x) rappresenta il gradiente della funzione obiettivo f in x. Questa condizione impone che il gradiente non cresca troppo velocemente, e che la funzione costo sia sufficientemente regolare. 
Step-size (o learning rate) : Il passo di aggiornamento ğœ‚ deve essere scelto in base alla costante di Lipschitz L. In particolare, per garantire la convergenza, il passo ğœ‚ deve essere minore o uguale a 1/L. Questa condizione assicura che il passo non sia troppo grande rispetto alla crescita del gradiente, limitando cosÃ¬ la possibilitÃ  di oscillazioni e garantendo la convergenza del metodo. Sotto queste condizioni, il metodo di discesa del gradiente converge a un punto stazionario della funzione costo, che puÃ² essere un minimo globale se la funzione Ã¨ convessa. Tuttavia, ğœ‚ fisso puÃ² essere limitante in termini di efficienza e velocitÃ  di convergenza.

Non convessitÃ  della funzione di costo.
quasi tutti i problemi di ottimizzazione in Deep Learning sono non convessi 
introducendo la non linearitÃ  nella rete (aggiungendo strati nascosti), la funzione costo diventa non convessa e compaiono i minimi locali, e si creano 2 casi:
il gradiente si annulla senza raggiungere il minimo globale , una zona piatta(vanishing gradient), oppure rimane bloccato in un minimo locale.


Importanza del learning rate nei metodi di discesa.
Valori bassi di learning rate possono far sÃ¬ che sia necessario un numero elevato di passi prima che lâ€™allenamento sia completato, e possono far sÃ¬ che i pesi rimangano bloccati in un minimo locale.
Valori alti di learning rate permettono di mitigare questi problemi,ma i pesi possono perÃ² anche finire per superare il minimo target

Exact line search.
La dimensione ottimale del learning rate puÃ² essere trovata risolvendo un problema di ottimizzazione unidimensionale 
ğœ‚ (ğ‘˜) = arg minğœ‚â‰¥0 ğ¶(ğ‘¤(ğ‘˜) + ğœ‚ğ‘ (ğ‘˜) )
dove ğ‘ (ğ‘˜) Ã¨ la direzione di discesa. 
Gli algoritmi di ottimizzazione unidimensionale per trovare la dimensione del passo ottimale sono genericamente chiamati exact line search 

Inexact line search rule , Armijo rule.
inexact line search rule . 
a prima Ã¨ stata Armijo rule ,consente di trovare uno step-size ğœ‚ appropriato che garantisca una riduzione significativa della funzione costo, garantendo convergenza dell'algoritmo. si basa sul concetto di "backtracking", che prevede di ridurre gradualmente la dimensione del passo. L'idea principale Ã¨ che, partendo da un certo punto iniziale, si riduca progressivamente la dimensione del passo moltiplicandola per il parametro ğœ (0 < ğœ < 1). Questo processo viene ripetuto fino a quando la condizione di Armijo Ã¨ soddisfatta . Se questa condizione viene soddisfatta 
ğ¶(ğ‘¤(ğ‘˜) + ğœ‚ğ‘ (ğ‘˜) ) â‰¤ ğ¶(ğ‘¤ (ğ‘˜) ) + ğœ â‹… ğœ‚ âˆ‡ğ¶(ğ‘¤ (ğ‘˜) ) ğ‘‡ ğ‘ (ğ‘˜) 
allora il passo ğœ‚ viene accettato; altrimenti, il passo viene ridotto di un fattore ğœ e il processo viene ripetuto. Armijo rule: parte con ğœ‚ = ğœ‚0 e lo fa decrescere moltiplicandolo per ğœ âˆˆ (0,1), finchÃ¨ la funzione descresce sufficientemente.


Metodo di ottimizzazione del gradient descent con momento. 
Il Gradient Descent con momento viene utilizzato per risolvere i problemi elencati. Si definisce la velocitÃ  ğ‘£ğ‘˜ = ğ›½ğ‘£ğ‘˜âˆ’1 + âˆ‡ğ¶(ğ‘¤ğ‘˜) 
ğ›½ prende il nome di momento e puÃ² variare tra 0 ed 1. 
ğ‘£0 viene inizializzato a zero. 
La formula di aggiornamento dei pesi diventa: ğ‘¤ğ‘˜+1 = ğ‘¤ğ‘˜ âˆ’ ğœ‚ğ‘£ğ‘˜ Se si pone ğ›½ = 0, si ricade nel classico metodo del gradiente. Un valore appropriato Ã¨ tra 0.8 e 0.9. Questo metodo aggiunge al gradiente istantaneo la media pesata esponenzialmente su piÃ¹ gradienti passati . Di seguito verifichiamo che ğ‘£ğ‘˜ rappresenta la media pesata esponenzialmente dei gradienti passati fino a quello al passo k

PerchÃ¨ Ã¨ stato studiato e formula di aggiornamento dei pesi.
Il metodo SGD con Momento aggiunge la â€œcronologiaâ€ agli aggiornamenti dei parametri dei problemi di discesa, il che accelera notevolmente il processo di ottimizzazione. La nuova sostituzione del gradiente non punta piÃ¹ nella direzione della discesa piÃ¹ ripida in un caso particolare, ma piuttosto nella direzione di una media ponderata esponenziale dei gradienti passati. In questo modo si ottiene una piÃ¹ veloce convergenza e si riduce l'oscillazione. In questo modo la scelta del learning rate Ã¨ meno cruciale poichÃ© la procedura di training si adatta alla particolare loss function.
ğ‘£ğ‘˜ = âˆ‘ğ›½ ğ‘˜âˆ’ğ‘— ğ‘˜ ğ‘—=1 âˆ‡ğ¶(ğ‘¤ğ‘—)



Iperparametri di una rete neurale.
Gli iperparametri sono parametri esterni al modello di machine learning che devono essere impostati prima dell'avvio del processo di addestramento. Gli iperparametri determinano come avviene l'addestramento del modello e possono includere: 
1.Learning rate : Determina quanto velocemente o lentamente il modello si adatta ai dati. 2.Numero di epoche: il numero di volte in cui l'intero set di dati di addestramento viene utilizzato per addestrare il modello. Un numero insufficiente puÃ² portare a un modello non addestrato adeguatamente, mentre un numero eccessivo puÃ² portare a un overfitting. 
3.Dimensione del mini-batch: il numero di esempi di addestramento utilizzati in ciascuna iterazione dell'algoritmo di ottimizzazione (ad esempio, SGD o mini-batch GD). La dimensione del mini-batch puÃ² influenzare la velocitÃ  di apprendimento e la stabilitÃ  dell'addestramento.
4.Regolarizzazione: i parametri che controllano la regolarizzazione del modello, come il peso della regolarizzazione L1 o L2, che influenzano la complessitÃ  del modello e la tendenza all'overfitting. 
5.Inizializzazione dei pesi: il metodo utilizzato per inizializzare i pesi puÃ² favorire una convergenza piÃ¹ rapida e una migliore performance. 
6.Funzione di attivazione: la funzione utilizzata per calcolare l'output di un'unitÃ  nel modello. Le funzioni di attivazione piÃ¹ comuni includono ReLU, sigmoid e tanh.
7. Architettura del modello: la struttura del modello, inclusi il numero di strati, il numero di unitÃ  in ciascun strato e le connessioni tra gli strati. La scelta dell'architettura dipende dal problema e dai dati specifici.

learning rate scheduling: step decay, decadimento esponenziale, decadimento dipendente dal tempo.
Esistono tre tipi comuni di implementazione del decadimento del learning rate: 
â€¢Step decay : riduce il tasso di apprendimento iniziale ğœ‚0 di un fattore ğ›¿ ogni numero predefinito di epoche ğ‘   n = n0 â‹… ğ›¿^|n/ğ‘ | dove n0 e ğ›¿ e ğ‘  sono iperparametri e s Ã¨ il numero di epoche eseguite 
â€¢ Il decadimento esponenziale ha la forma matematica n = n0 â‹… ğ‘’^âˆ’ğ‘˜ğ‘¡ 
dove ğœ‚0 e ğ‘˜ sono iperparametri e ğ‘¡ Ã¨ il numero di iterazione corrente 
â€¢ Il decadimento basato sul tempo divide il learning rate iniziale ğœ‚0 in funzione del numero di iterazioni eseguite (ğ‘¡) ğœ‚ = ğœ‚0 1 + ğ‘˜ â‹… ğ‘¡ dove ğœ‚0 e ğ‘˜ sono iperparametri 
In alcuni casi, l'inizializzazione casuale dei parametri non garantisce una buona soluzione soprattutto se all'inizio viene utilizzato un learning rate grande che porta alla divergenza Questo problema puÃ² essere affrontato scegliendo un learning rate sufficientemente piccolo ma molto lento. Una soluzione consiste nell'utilizzare un periodo di warm-up: si inizia con un learning rate molto inferiore al learning rate "iniziale" e poi lo si aumenta in alcune iterazioni o epoche fino a raggiungere quel learning rate "iniziale" e poi lo si riduce fino alla fine del processo di ottimizzazione.

Learning rate adattivo: Adagrad, RMSProp, Adadelta, Adam.
Adagrad adatta il Learning Rate ai parametri, eseguendo aggiornamenti piÃ¹ grandi per i parametri poco frequenti e aggiornamenti piÃ¹ piccoli per quelli frequenti.
Adagrad elimina la necessitÃ  di regolare manualmente il learning rate Il principale punto debole Ã¨ l'accumulo dei gradienti al quadrato durante l'addestramento la somma accumulata cresce, il learning rate diminuisce diventando infinitesimamente piccolo fino a che non Ã¨ piÃ¹ in grado di apprendere.
RMSProp Ã¨ stato introdotto per ridurre la diminuzione aggressiva del learning rate di Adagrad. Modifica la parte di accumulo del gradiente di Adagrad con una media ponderata esponenziale dei gradienti al quadrato invece della somma dei gradienti al quadrato
Adadelta Ã¨ un'altra variante di Adagrad .Come RMSProp calcola l'accumulo del gradiente come una media ponderata esponenziale dei gradienti al quadrato ma, a differenza di RMSProp, non richiede di impostare un learning rate in quanto utilizza la quantitÃ  di cambiamento stessa come calibrazione per il cambiamento futuro
